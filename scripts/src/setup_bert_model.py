#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½BERTæ¨¡å‹ - ä½¿ç”¨å›½å†…é•œåƒ
"""

import os
import sys
from transformers import BertTokenizer, BertForSequenceClassification
import torch
import requests
import time

def download_with_retry(model_name, save_path, max_retries=3):
    """å¸¦é‡è¯•çš„ä¸‹è½½å‡½æ•°"""
    
    # è®¾ç½®é•œåƒæº
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    
    for attempt in range(max_retries):
        try:
            print(f"[INFO] å°è¯• {attempt + 1}/{max_retries}...")
            
            # ä¸‹è½½tokenizer
            print("ä¸‹è½½tokenizer...")
            tokenizer = BertTokenizer.from_pretrained(
                model_name,
                cache_dir="./cache/huggingface"
            )
            tokenizer.save_pretrained(save_path)
            print(f"[OK] tokenizerä¿å­˜åˆ°: {save_path}")
            
            # ä¸‹è½½æ¨¡å‹
            print("ä¸‹è½½æ¨¡å‹...")
            model = BertForSequenceClassification.from_pretrained(
                model_name,
                num_labels=3,
                torch_dtype=torch.float32,
                cache_dir="./cache/huggingface"
            )
            model.save_pretrained(save_path)
            print(f"[OK] æ¨¡å‹ä¿å­˜åˆ°: {save_path}")
            
            return True
            
        except Exception as e:
            print(f"[ERROR] å°è¯• {attempt + 1} å¤±è´¥: {e}")
            
            if attempt < max_retries - 1:
                print(f"[INFO] ç­‰å¾… {2 ** attempt} ç§’åé‡è¯•...")
                time.sleep(2 ** attempt)
                
                # å°è¯•å…¶ä»–é•œåƒæº
                if attempt == 1:
                    os.environ['HF_ENDPOINT'] = 'https://mirror.sjtu.edu.cn/hugging-face'
                    print("[INFO] åˆ‡æ¢åˆ°ä¸Šæµ·äº¤é€šå¤§å­¦é•œåƒ...")
                elif attempt == 2:
                    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
                    print("[INFO] åˆ‡æ¢å›hf-mirroré•œåƒ...")
            else:
                return False
    
    return False

def download_bert_model_manual():
    """æ‰‹åŠ¨ä¸‹è½½BERTæ¨¡å‹ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
    print("\n[INFO] å°è¯•æ‰‹åŠ¨ä¸‹è½½...")
    
    model_name = "bert-base-chinese"
    save_path = "./models/bert-base-chinese"
    
    os.makedirs(save_path, exist_ok=True)
    
    # æ–‡ä»¶åˆ—è¡¨
    files = [
        ("config.json", "æ¨¡å‹é…ç½®æ–‡ä»¶"),
        ("vocab.txt", "è¯æ±‡è¡¨æ–‡ä»¶"),
        ("pytorch_model.bin", "æ¨¡å‹æƒé‡æ–‡ä»¶"),
        ("tokenizer_config.json", "tokenizeré…ç½®æ–‡ä»¶"),
        ("special_tokens_map.json", "ç‰¹æ®Štokenæ˜ å°„")
    ]
    
    # é•œåƒæºURLæ¨¡æ¿
    base_urls = [
        "https://hf-mirror.com/bert-base-chinese/resolve/main/{}",
        "https://mirror.sjtu.edu.cn/hugging-face/bert-base-chinese/resolve/main/{}"
    ]
    
    for filename, description in files:
        print(f"ä¸‹è½½ {description} ({filename})...")
        
        downloaded = False
        for base_url in base_urls:
            url = base_url.format(filename)
            try:
                response = requests.get(url, timeout=30, stream=True)
                if response.status_code == 200:
                    file_path = os.path.join(save_path, filename)
                    with open(file_path, 'wb') as f:
                        for chunk in response.iter_content(chunk_size=8192):
                            f.write(chunk)
                    print(f"  [OK] ä» {base_url.split('/')[2]} ä¸‹è½½æˆåŠŸ")
                    downloaded = True
                    break
            except Exception as e:
                print(f"  [ERROR] ä» {base_url.split('/')[2]} ä¸‹è½½å¤±è´¥: {e}")
        
        if not downloaded:
            print(f"  [WARNING] {filename} ä¸‹è½½å¤±è´¥")
    
    # æ£€æŸ¥æ˜¯å¦ä¸‹è½½äº†å¿…è¦æ–‡ä»¶
    required_files = ['config.json', 'vocab.txt', 'pytorch_model.bin']
    missing_files = []
    
    for filename in required_files:
        if not os.path.exists(os.path.join(save_path, filename)):
            missing_files.append(filename)
    
    if missing_files:
        print(f"[ERROR] ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
        return False
    else:
        print("[OK] æ‰‹åŠ¨ä¸‹è½½å®Œæˆ")
        return True

def download_with_proxy():
    """ä½¿ç”¨ä»£ç†ä¸‹è½½"""
    print("\n[INFO] å°è¯•ä½¿ç”¨ä»£ç†ä¸‹è½½...")
    
    # è®¾ç½®ä»£ç†ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    proxies = {
        'http': 'http://127.0.0.1:7890',
        'https': 'http://127.0.0.1:7890',
    }
    
    model_name = "bert-base-chinese"
    save_path = "./models/bert-base-chinese"
    
    os.makedirs(save_path, exist_ok=True)
    
    try:
        # å°è¯•ä½¿ç”¨ä»£ç†ä¸‹è½½
        print("è®¾ç½®ä»£ç†ä¸‹è½½...")
        
        # å…ˆä¸‹è½½tokenizer
        tokenizer = BertTokenizer.from_pretrained(
            model_name,
            proxies=proxies,
            cache_dir="./cache/huggingface"
        )
        tokenizer.save_pretrained(save_path)
        print("[OK] tokenizerä¸‹è½½å®Œæˆ")
        
        # ä¸‹è½½æ¨¡å‹
        model = BertForSequenceClassification.from_pretrained(
            model_name,
            num_labels=3,
            torch_dtype=torch.float32,
            proxies=proxies,
            cache_dir="./cache/huggingface"
        )
        model.save_pretrained(save_path)
        print("[OK] æ¨¡å‹ä¸‹è½½å®Œæˆ")
        
        return True
        
    except Exception as e:
        print(f"[ERROR] ä»£ç†ä¸‹è½½å¤±è´¥: {e}")
        return False

def create_minimal_bert_model():
    """åˆ›å»ºæœ€å°åŒ–çš„BERTæ¨¡å‹ï¼ˆæœ€åæ‰‹æ®µï¼‰"""
    print("\n[INFO] åˆ›å»ºæœ€å°åŒ–BERTæ¨¡å‹...")
    
    save_path = "./models/bert-base-chinese"
    os.makedirs(save_path, exist_ok=True)
    
    try:
        # åˆ›å»ºtokenizer
        from transformers import BertTokenizer
        
        print("åˆ›å»ºtokenizer...")
        tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
        
        # åˆ›å»ºæœ€å°é…ç½®
        config = {
            "architectures": ["BertForSequenceClassification"],
            "attention_probs_dropout_prob": 0.1,
            "gradient_checkpointing": False,
            "hidden_act": "gelu",
            "hidden_dropout_prob": 0.1,
            "hidden_size": 768,
            "initializer_range": 0.02,
            "intermediate_size": 3072,
            "layer_norm_eps": 1e-12,
            "max_position_embeddings": 512,
            "model_type": "bert",
            "num_attention_heads": 12,
            "num_hidden_layers": 12,
            "pad_token_id": 0,
            "position_embedding_type": "absolute",
            "transformers_version": "4.36.0",
            "type_vocab_size": 2,
            "use_cache": True,
            "vocab_size": 21128,
            "num_labels": 3,
            "id2label": {"0": "positive", "1": "negative", "2": "neutral"},
            "label2id": {"positive": 0, "negative": 1, "neutral": 2}
        }
        
        import json
        with open(os.path.join(save_path, "config.json"), 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜tokenizer
        tokenizer.save_pretrained(save_path)
        
        print("[OK] æœ€å°åŒ–BERTæ¨¡å‹åˆ›å»ºå®Œæˆ")
        print("[WARNING] è¿™æ˜¯ä¸€ä¸ªæœ€å°åŒ–æ¨¡å‹ï¼Œæ€§èƒ½å¯èƒ½ä¸å¦‚å®Œæ•´æ¨¡å‹")
        
        return True
        
    except Exception as e:
        print(f"[ERROR] åˆ›å»ºæœ€å°åŒ–æ¨¡å‹å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ä¸‹è½½BERTæ¨¡å‹ - å¤šç§ä¸‹è½½æ–¹å¼")
    print("=" * 70)
    
    model_name = "bert-base-chinese"
    save_path = "./models/bert-base-chinese"
    
    # åˆ›å»ºç›®å½•
    os.makedirs(save_path, exist_ok=True)
    os.makedirs("./cache/huggingface", exist_ok=True)
    
    print(f"[INFO] ç›®æ ‡æ¨¡å‹: {model_name}")
    print(f"[INFO] ä¿å­˜è·¯å¾„: {save_path}")
    print("[INFO] ä¼˜å…ˆä½¿ç”¨å›½å†…é•œåƒ...")
    print()
    
    # æ–¹æ³•1: ä½¿ç”¨é•œåƒæºä¸‹è½½
    print("æ–¹æ³•1: ä½¿ç”¨é•œåƒæºä¸‹è½½")
    print("-" * 40)
    success = download_with_retry(model_name, save_path)
    
    if not success:
        print("\næ–¹æ³•1å¤±è´¥ï¼Œå°è¯•æ–¹æ³•2...")
        
        # æ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½
        print("\næ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½æ–‡ä»¶")
        print("-" * 40)
        success = download_bert_model_manual()
    
    if not success:
        print("\næ–¹æ³•2å¤±è´¥ï¼Œå°è¯•æ–¹æ³•3...")
        
        # æ–¹æ³•3: ä½¿ç”¨ä»£ç†
        print("\næ–¹æ³•3: ä½¿ç”¨ä»£ç†ä¸‹è½½")
        print("-" * 40)
        success = download_with_proxy()
    
    if not success:
        print("\næ‰€æœ‰ä¸‹è½½æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•æ–¹æ³•4...")
        
        # æ–¹æ³•4: åˆ›å»ºæœ€å°åŒ–æ¨¡å‹
        print("\næ–¹æ³•4: åˆ›å»ºæœ€å°åŒ–BERTæ¨¡å‹")
        print("-" * 40)
        success = create_minimal_bert_model()
    
    # æ£€æŸ¥ç»“æœ
    if success:
        print("\n" + "=" * 70)
        print("âœ… BERTæ¨¡å‹è®¾ç½®å®Œæˆ!")
        print("=" * 70)
        
        # æ£€æŸ¥æ–‡ä»¶
        print("\n[CHECK] æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶:")
        files = os.listdir(save_path)
        for file in files:
            file_path = os.path.join(save_path, file)
            if os.path.isfile(file_path):
                size = os.path.getsize(file_path)
                size_str = f"{size/1024:.1f} KB" if size < 1024*1024 else f"{size/(1024*1024):.1f} MB"
                print(f"  - {file} ({size_str})")
        
        print(f"\nğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {save_path}")
        print("\n[INFO] ç°åœ¨å¯ä»¥è¿è¡Œ:")
        print("1. è®­ç»ƒæ¨¡å‹: python main.py --train-bert")
        print("2. å®Œæ•´æµç¨‹: python main.py --all")
        
        return True
    else:
        print("\n" + "=" * 70)
        print("âŒ BERTæ¨¡å‹ä¸‹è½½å¤±è´¥!")
        print("=" * 70)
        print("\n[SOLUTION] è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. å°è¯•æ‰‹åŠ¨ä¸‹è½½:")
        print("   - è®¿é—®: https://hf-mirror.com/bert-base-chinese")
        print("   - ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶åˆ° models/bert-base-chinese/ ç›®å½•:")
        print("     - config.json")
        print("     - pytorch_model.bin")
        print("     - vocab.txt")
        print("     - tokenizer_config.json")
        print("3. æˆ–è¿è¡Œ: python train_simple.py ä½¿ç”¨ç®€å•æ¨¡å‹")
        
        return False

if __name__ == "__main__":
    main()